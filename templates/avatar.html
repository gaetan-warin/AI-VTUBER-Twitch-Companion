<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>Interactive Live2D Avatar</title>
    <link rel="icon" href="static/favicon.ico" type="image/x-icon">

    <script src="https://cubism.live2d.com/sdk-web/cubismcore/live2dcubismcore.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/dylanNew/live2d/webgl/Live2D/lib/live2d.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/pixi.js@6.5.2/dist/browser/pixi.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/pixi-live2d-display/dist/index.min.js"></script>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/3.12.2/gsap.min.js"></script>
    <script src="https://cdn.socket.io/4.5.4/socket.io.min.js"></script>
    <link rel="stylesheet" href="static/style.css">
</head>
<body>
    <canvas id="canvas"></canvas>

    <div class="controls">
        <div class="input-group">
            <textarea id="text-input" placeholder="Enter text for the avatar to speak..."></textarea>
            <button id="speakBtn">Speak</button>
        </div>
    </div>

    <script>
        // WebSocket configuration
        const socket = io({
            transports: ['websocket'],
            reconnectionAttempts: 5,
            timeout: 3000
        });

        // Speech synthesis setup
        const synth = window.speechSynthesis;
        let isSpeaking = false;
        let mouthTween = null;
        let live2dModel = null;
        let voicesReady = false;

        // Live2D model configuration
        const cubism2Model = "model/shizuku/shizuku.model.json";

        // Initialize application
        (async function main() {
            // Set up PIXI application
            const app = new PIXI.Application({
                view: document.getElementById("canvas"),
                autoStart: true,
                resizeTo: window,
                backgroundAlpha: 0
            });

            try {
                // Load Live2D model
                live2dModel = await PIXI.live2d.Live2DModel.from(cubism2Model);
                app.stage.addChild(live2dModel);
                live2dModel.scale.set(0.3);
                
                // Wait for model to be fully loaded
                await new Promise(resolve => live2dModel.once('ready', resolve));

                const coreModel = live2dModel.internalModel.coreModel;

                window.mouthParamIndex = coreModel.getParameterIndex("PARAM_MOUTH_OPEN_Y");

                if (window.mouthParamIndex === -1) {
                    const parameterCount = coreModel.getParameterCount();
                    const parameterIds = Array.from({length: parameterCount}, (_, i) => coreModel.getParameterId(i));
                    console.log('All Parameters:', parameterIds);
                    
                    // Find mouth parameter index
                    window.mouthParamIndex = parameterIds.findIndex(id => 
                        id.toLowerCase().includes('mouth')
                    );

                    if (window.mouthParamIndex === -1) {
                        console.error('Mouth parameter not found in:', parameterIds);
                    }
                }


            console.log('Mouth parameter index:', window.mouthParamIndex);
            console.log('All parameters:', Array.from({length: coreModel.getParameterCount()}, 
                (_, i) => coreModel.getParameterId(i)));

            // Initial positioning
            updateModelPosition();
            window.addEventListener('resize', updateModelPosition);
                
                // Set up resize handler
                window.addEventListener('resize', updateModelPosition);
                updateModelPosition();

            } catch (error) {
                console.error('Model loading error:', error);
            }
        })();

        // Position handling
        function updateModelPosition() {
            if (!live2dModel) return;
            
            const isMobile = window.innerWidth <= 768;
            live2dModel.scale.set(isMobile ? 0.8 : 1.2);
            live2dModel.position.set(
                window.innerWidth / 2,
                window.innerHeight / 2 + 100
            );
        }

        // Speech functions
        function speak(text) {
            if (!text || !voicesReady) {
                console.log('Speech not ready');
                return;
            }

            if (isSpeaking) {
                synth.cancel();
                isSpeaking = false;
                mouthTween?.kill();
            }

            const utterance = new SpeechSynthesisUtterance(text);
            const voice = synth.getVoices().find(v => v.name.includes('Female')) || synth.getVoices()[0];

            Object.assign(utterance, {
                voice: voice,
                pitch: 1.1,
                rate: 0.95
            });

            utterance.onstart = () => {
                isSpeaking = true;
                let startTime = Date.now();
                const animationSpeed = 0.008 * (1.1 - utterance.rate); // Adjust based on speech rate
                
                mouthTween = gsap.to({}, {
                    duration: Infinity, // Continuous animation
                    onUpdate: () => {
                        if (!isSpeaking) return;
                        const time = (Date.now() - startTime) * animationSpeed;
                        // Smooth sine wave between 0.3 and 0.7
                        const value = Math.abs(Math.sin(time)) * 0.6 + 0.2;
                        animateMouth(value);
                    }
                });
            };

            utterance.onend = () => {
                isSpeaking = false;
                mouthTween?.kill();
                // Smooth close animation
                gsap.to({}, {
                    duration: 0.2,
                    onUpdate: () => animateMouth(0),
                    ease: "power2.out"
                });
            };

            synth.speak(utterance);
        }

        // Mouth animation
        function animateMouth(value) {
            if (live2dModel && window.mouthParamIndex !== undefined && window.mouthParamIndex !== -1) {
                const coreModel = live2dModel.internalModel.coreModel;
                coreModel.setParamFloat(window.mouthParamIndex, value);
                
                // Update model and request render
                live2dModel.internalModel.update();
                live2dModel.internalModel.coreModel.update();
                live2dModel.internalModel.requestUpdate();
            }
        }

        // Event listeners
        function setupEventListeners() {
            // Speech button handler
            document.getElementById('speakBtn').addEventListener('click', () => {
                const text = document.getElementById('text-input').value.trim();
                if (text) socket.emit('speak', { text });
            });

            // Socket.io events
            socket.on('speak_text', data => {
                console.log('Received speech text:', data.text);
                requestAnimationFrame(() => speak(data.text));
            });

            socket.on('connect', () => {
                console.log('WebSocket connected:', socket.id);
            });

            socket.on('disconnect', () => {
                console.log('WebSocket disconnected');
            });
        }

        // Voice initialization
        synth.onvoiceschanged = () => {
            voicesReady = true;
            console.log('Voices loaded:', synth.getVoices());
        };

        // Initial setup
        document.addEventListener('DOMContentLoaded', () => {
            setupEventListeners();
            socket.connect();
        });
    </script>
</body>
</html>