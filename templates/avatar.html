<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>AI CHAT BOT</title>
    <link rel="icon" href="static/favicon.ico" type="image/x-icon">

    <script src="static/live2dcubismcore.min.js"></script>
    <script src="static/live2d.min.js"></script>
    <script src="static/pixi.min.js"></script>
    <script src="static/browser.js"></script>

    <script src="static/gsap.min.js"></script>
    <script src="static/socket.io.min.js"></script>
    <link rel="stylesheet" href="static/style.css">
</head>
<body>
    <canvas id="canvas"></canvas>

    <div class="controls">
        <div class="input-group">
            <textarea id="text-input" placeholder="Enter text for the avatar to speak..."></textarea>
            <button id="speakBtn">Speak</button>
        </div>
    </div>

    <script>
        const modelPath = 'model/shizuku/shizuku.model.json';
        const synth = window.speechSynthesis;
        const mouthState = { value: 0 };
        let isSpeaking = false;
        let voicesReady = false;

        // WebSocket configuration
        const socket = io({
            transports: ['websocket'],
            reconnectionAttempts: 5,
            timeout: 3000
        });

        // Initialize application
        function main() {
            const app = new PIXI.Application({
                view: document.getElementById('canvas'),
                autoStart: true,
                resizeTo: window,
                transparent: true, 
                antialias: true
            });

            app.ticker.add(() => {
                // mimic the interpolation value, 0-1
                if(isSpeaking)
                    mouthState.value = Math.sin(performance.now() / 200) / 2 + 0.5;
            });
        
            try {
                PIXI.live2d.Live2DModel.fromModelSettingsFile(modelPath).then(model => {
                    app.stage.addChild(model);
                    
                    model.anchor.set(0.5, 0.5);
                    model.position.set(innerWidth / 2, innerHeight / 2);
                    
                    const size = Math.min(innerWidth, innerHeight) * 0.8;
                    model.width = size;
                    model.height = size;
                    
                    const updateFn = model.internal.motionManager.update;
                    model.internal.motionManager.update = () => {
                        updateFn.call(model.internal.motionManager);
                        model.internal.coreModel.setParamFloat('PARAM_MOUTH_OPEN_Y', mouthState.value);
                    }
                });
            } catch (error) {
                console.error('Model loading error:', error);
            }
        }

        // Voice initialization
        synth.onvoiceschanged = () => {
            voicesReady = true;
            console.log('Voices loaded:', synth.getVoices());
        };

        // Speech functions
        function speak(text) {
            if (!text || !voicesReady) {
                console.log("Voices not loaded yet.");
                return;
            }

            if (isSpeaking) {
                synth.cancel();
                isSpeaking = false;
                gsap.killTweensOf(mouthState);
            }

            // Split text into chunks based on sentence endings (., !, ?)
            const sentenceEndRegex = /([.!?])\s*/g;
            const sentences = [];
            let lastIndex = 0;

            // Capture sentences
            while ((match = sentenceEndRegex.exec(text)) !== null) {
                const sentence = text.slice(lastIndex, match.index + match[0].length).trim();
                if (sentence) {
                    sentences.push(sentence);
                }
                lastIndex = match.index + match[0].length;
            }

            // Add remaining text if any
            if (lastIndex < text.length) {
                sentences.push(text.slice(lastIndex).trim());
            }

            let sentenceIndex = 0;

            // Function to speak each sentence
            function speakNextSentence() {
                if (sentenceIndex < sentences.length) {
                    const utterance = new SpeechSynthesisUtterance(sentences[sentenceIndex]);
                    const voice = synth.getVoices().find(v => v.name.includes('Female')) || synth.getVoices()[0];

                    Object.assign(utterance, {
                        voice: voice,
                        pitch: 1.1,
                        rate: 0.95
                    });

                    utterance.onstart = () => {
                        isSpeaking = true;
                        // Animate mouth using GSAP with sine wave pattern
                        gsap.to(mouthState, {
                            duration: 0.2,
                            value: 1,
                            repeat: -1,
                            yoyo: true,
                            ease: "sine.inOut",
                            modifiers: {
                                value: () => Math.abs(Math.sin(performance.now() / 200)) * 0.8
                            }
                        });
                    };

                    utterance.onend = () => {
                        sentenceIndex++;
                        if (sentenceIndex < sentences.length) {
                            speakNextSentence(); // Speak the next sentence
                        } else {
                            isSpeaking = false;
                            gsap.killTweensOf(mouthState);
                            gsap.to(mouthState, {
                                duration: 0.3,
                                value: 0,
                                ease: "power2.out"
                            });
                        }
                    };

                    synth.speak(utterance);
                }
            }

            speakNextSentence(); // Start speaking the first sentence
        }


        function setupEventListeners() {
            document.getElementById('speakBtn').addEventListener('click', () => {
                const text = document.getElementById('text-input').value.trim();
                if (text) socket.emit('speak', { text });
            });

            socket.on('speak_text', data => {
                console.log("Received text to speak:", data.text);
                speak(data.text);
            });
            
            socket.on('connect', () => console.log('WebSocket connected:', socket.id));
            socket.on('disconnect', () => console.log('WebSocket disconnected'));
        }

        // Initial setup
        document.addEventListener('DOMContentLoaded', () => {
            setupEventListeners();
            socket.connect();
            main();
        });
    </script>
</body>
</html>